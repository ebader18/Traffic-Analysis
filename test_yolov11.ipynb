{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track all ojects using bounding box in video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference with the YOLO11n model on the 'bus.jpg' image\n",
    "results = model.track(\"video_001.mp4\", save=True, show=True, tracker='bytetrack.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track all ojects using segmentation in video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11x-seg.pt\")  # load an official model\n",
    "# model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model.track(source=\"video_001.mp4\", save=True)  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track all objeects using segmentation once image at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "filename = 'video_001'\n",
    "model = YOLO(\"yolo11x-seg.pt\")  # segmentation model\n",
    "cap = cv2.VideoCapture(f'{filename}.mp4')\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(f'{filename}_x_instance-segmentation-object-tracking.mp4', cv2.VideoWriter_fourcc(*\"H265\"), fps, (w, h))\n",
    "\n",
    "idx_frame = 0\n",
    "while True:\n",
    "    ret, im0 = cap.read()\n",
    "    idx_frame += 1\n",
    "    if not ret or idx_frame == -1:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "    results = model.track(im0, persist=True)\n",
    "\n",
    "    if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "        masks = results[0].masks.xy\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        track_cls = [results[0].names[i] for i in results[0].boxes.cls.int().cpu().tolist()]\n",
    "\n",
    "        #for mask, track_id in zip(masks, track_ids):\n",
    "        for mask, track_cl in zip(masks, track_cls):\n",
    "            #color = colors(int(track_id), True)\n",
    "            color = colors(0, True)\n",
    "            txt_color = annotator.get_txt_color(color)\n",
    "            #annotator.seg_bbox(mask=mask, mask_color=color, label=str(track_id), txt_color=txt_color)\n",
    "            annotator.seg_bbox(mask=mask, mask_color=color, label=str(track_cl), txt_color=txt_color)\n",
    "\n",
    "    out.write(im0)\n",
    "    cv2.imshow(f'{filename}video_002_trimmed_instance-segmentation-object-tracking', im0)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track specific object using segmentation one image at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "from queue import Queue\n",
    "import numpy as np\n",
    "\n",
    "class ObjectTracker:\n",
    "    def __init__(self, model_path=\"yolo11x-seg.pt\", track_class=\"car\"):\n",
    "        \"\"\"\n",
    "        Initialize the ObjectTracker with the specified model and class to track.\n",
    "\n",
    "        :param model_path: Path to the YOLO model.\n",
    "        :param track_class: Name of the class to track (default is 'car').\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.track_class = track_class\n",
    "\n",
    "    def process_image(self, image):\n",
    "        \"\"\"\n",
    "        Process an image to detect and segment the specified object class.\n",
    "\n",
    "        :param image: The input image.\n",
    "        :return: A tuple containing the original image and a list of tracking results, where each result includes the object ID, the masked image, and the top-left coordinate.\n",
    "        \"\"\"\n",
    "        results = self.model.track(image, persist=True)\n",
    "        output_data = []\n",
    "\n",
    "        if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "            masks = results[0].masks.xy\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            track_cls = [results[0].names[i] for i in results[0].boxes.cls.int().cpu().tolist()]\n",
    "\n",
    "            for mask, obj_id, track_cl in zip(masks, track_ids, track_cls):\n",
    "                if track_cl == self.track_class:\n",
    "                    # Apply the mask to the original image\n",
    "                    masked_image = self.apply_mask(image, mask)\n",
    "                    output_data.append({\n",
    "                        \"object_id\": obj_id,\n",
    "                        \"masked_image\": masked_image,\n",
    "                        \"top_left\": (0, 0)  # Always (0, 0) as we keep the original size\n",
    "                    })\n",
    "        return output_data\n",
    "\n",
    "    def apply_mask(self, image, mask):\n",
    "        \"\"\"\n",
    "        Apply the mask to the image while keeping the original size, \n",
    "        setting everything outside the mask to black.\n",
    "\n",
    "        :param image: The original image.\n",
    "        :param mask: The mask coordinates.\n",
    "        :return: The masked image with the same size as the original.\n",
    "        \"\"\"\n",
    "        # Create a blank mask of the same size as the image\n",
    "        mask_image = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        # Draw the polygon mask on the blank image\n",
    "        cv2.fillPoly(mask_image, [np.array(mask, dtype=np.int32)], 255)\n",
    "\n",
    "        # Apply the mask to the original image\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=mask_image)\n",
    "\n",
    "        return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "# sys.path.append(os.path.abspath('../Live-Pose-Estimator'))\n",
    "# from pose_estimator import pose_estimator\n",
    "\n",
    "FILENAME = 'video_002'\n",
    "TRACK_CLASS = 'car'\n",
    "\n",
    "cap = cv2.VideoCapture(f'{FILENAME}.mp4')\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "tracker = ObjectTracker(track_class=\"car\")  # Initialize tracker for cars\n",
    "\n",
    "'''\n",
    "# Principal point (assuming the center of the image)\n",
    "cx, cy = w / 2, h / 2\n",
    "# Convert FOV from degrees to radians\n",
    "fov_x, fov_y = 70, 50\n",
    "fov_x_rad, fov_y_rad = np.deg2rad(fov_x), np.deg2rad(fov_y)\n",
    "# Focal lengths in pixels\n",
    "fx, fy = w / (2 * np.tan(fov_x_rad / 2)), h / (2 * np.tan(fov_y_rad / 2))\n",
    "# Intrinsic matrix\n",
    "K = np.array([[fx, 0, cx],\n",
    "                [0, fy, cy],\n",
    "                [0, 0, 1]])\n",
    "\n",
    "pose = pose_estimator(K, max_feature=10000, print_messages=True, size_output_img=[3000, 2400])'''\n",
    "\n",
    "idx_frame = 0\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    idx_frame += 1\n",
    "    if not ret or idx_frame == -1:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Retrieve and process results if available\n",
    "    tracked_objects = tracker.process_image(image)\n",
    "    if tracked_objects:\n",
    "        # Use only the first detected car's masked image\n",
    "        first_car = tracked_objects[0]\n",
    "        masked_image = first_car[\"masked_image\"]\n",
    "\n",
    "        '''ret, R, t, match_img = pose.compute_pose(masked_image)\n",
    "        if ret:\n",
    "            cv2.imshow('Matched image', match_img)'''\n",
    "\n",
    "        cv2.imshow('Masked Car', masked_image)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
